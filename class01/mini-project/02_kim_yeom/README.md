![image](https://github.com/kccistc/intel-04/assets/127078552/e56a1c14-40fe-40bf-833c-dd0b85b4574b)

# 개요 및 소개

[![Typing SVG](https://readme-typing-svg.demolab.com?font=Dongle&size=60&pause=1000&color=F249F7&background=FFFFFF8D&repeat=false&random=false&width=800&lines=+%EC%9D%8C%EC%84%B1+%EC%9D%B8%EC%8B%9D%EB%B0%8F+%EC%9D%8C%EC%84%B1+%EB%8C%80%EB%8B%B5+AI%2C+%EB%A7%90%ED%95%98%EB%8A%94+GPT)](https://git.io/typing-svg)

<br>   

# 팀원역활     

<br>   

- #### 염재영: 텍스트-> 음성 변환 모델 검토&확인, 3가지 모델 병합 작업, PPT 작성 및 발표

- #### 김기범: 음성 -> 텍스트 변환 모델 검토&확인, GPT 모델 검토 및 확인, 3가지 모델 병합 작업, 프로젝트 시연 및 결과 검토

     
<br>  

   
<br>   
   
# 프로젝트 문제 정의

1. 다양한 플랫폼 및 장치 호환성의 필요성: 음성 AI가 다양한 소프트웨어 및 하드웨어 플랫폼에서도 원활하게 동작할 수 있는 유연성이 요구됨.

2. 높아진 사용자의 AI와의 소통 기대치: 대부분의 음성 인식 시스템은 사용자와의 자연스러운 대화를 제공하지 못해 사용자 경험이 제한됨

3. 높은 성능 요구의 필요성: 실시간 대화 시스템에서는 뛰어난 성능이 요구되는데, 이를 충족시키는 음성 AI 시스템의 중요성이 부각됨.
   
<br>   

# 프로젝트 목표

1. 다양한 플랫폼 및 장치 호환성 제공: 다양한 소프트웨어 및 하드웨어 플랫폼에서 호환되는 음성 인식 및 음성 대답 시스템 구축.
    
2. 자연스러운 응답 기능 제공: 사용자와의 자연스러운 대화를 위한 음성 AI 시스템 개발.

3. 서버 의존성 최소화 가능성 제공: Openvino zoo의 모델세트 코드 및 모델만을 활용하여 딥러닝 처리 부분을 경량화
    
4. 핵심 프로젝트를 위한 기반 기능 구현: 진행될 키오스크 음성 지원 시스템을 위한 음성 인식 및 응답 AI 구축
   
<br>   
   
# 시장 조사
음성 인식 및 대화형 AI 시장은 현재 급격한 성장을 경험하고 있습니다. 
인공 지능 기술의 발전과 함께 스마트 홈 장치, 자동차 인포테인먼트 시스템, 의료 및 교육 분야에서의 적용 등 다양한 영역에서 활용이 확대되고 있습니다. 
또한, 사용자 경험의 향상과 효율성 증대를 위해 기업들은 음성 AI 기술에 대한 투자를 늘리고 있습니다. 
이러한 시장 동향을 고려하여 우리 프로젝트는 시장의 수요를 충족시키고 미래 시장에서 경쟁력을 확보할 수 있는 기술을 개발하는 데 주력할 것입니다.
   
<br>   
   
# 시스템 디자인 구상도
![Untitled Diagram drawio](https://github.com/kccistc/intel-04/assets/165994180/50373d35-aadc-4579-9411-e2de5274a67a)

   
<br>   

#### 세부 시스템 개발 구상도
![image](https://github.com/kccistc/intel-04/assets/127078552/47821ce5-ab8e-44f3-b06e-23fe1bcc2221)


<br>   
   
# 시스템 기술 구성도
- #### 10초동안 마이크 입력을 받아서 이를 .wav파일로 변환하는 코드
- #### 음성 -> 텍스트로 변환하는 모델
- #### 받은 음성에 대한 적절한 대답을 하는 LLM 모델
- #### 텍스트 -> 음성으로 변환하여 출력하는 모델
   
<br>   
   
# 개발 진행
   
<br>   
   
### 1. 실시간 음성 녹음
- ### 마이크 입력을 .wav파일로 변환하는 과정을 추가
#### 원래 speech_recognition 모델 코드 세트들의 실행 인자 값으로 -i <장치>를 할려 했으나 wav2vec 모델 세트만 정상적으로 동작하였다. 
#### 해당 speech_recognition_wav2vec 모델은 오직 장치 입력이 아닌 .wav파일만을 처리해서 해당 마이크 입력을 변환하는 과정을 추가하였다.

<br>   
   
### 2. 음성 -> 텍스트로 변환하는 과정
- #### 음성이 변환된 해당 .wav 파일을 텍스트로 변환하도록 speech_recognition_wav2vec 모델 세트 코드를 활용하여 해당 .wav파일을 input.txt파일로 출력하였다.
   
<br>   
   
### 3. GPT로 입력받은 변환하는 과정
- #### 출력된 음성 입력인 inpuit.txt의 내용을 받아서 GPT-2로 입력으로 넣어 output.txt로 내용을 출력하였다.
   
<br>   
   
### 4. 텍스트 -> 음성으로 변환하는 과정
- #### 출력된 LLM모델의 예상 답변인 output.txt를 읽어서 다시 text_to_speech 모델 세트 코드를 활용해서 audio.wav로 출력하였다.
   
<br>   
   
### 5. 과정 병합
- #### 각각의 과정을 os 라이브러리를 활용해서 기존의 각각의 코드를 실행하는 명령어 형식으로 연결하였다.
- #### 기존의 1번과 2번 과정에서 프롬프트 형식의 출력을 파일로 출력될 수 있도록 코드 및 옵션을 추가로 넣었다. 
   
<br>    

# 프로젝트 시연 결과
* 음량 품질에 따른 출력 결과가 달라져서 입력 장치의 성능이 낮은 장치부터 높은 장치 순으로 시연해보았다.
  
## PLEOMAX W-210 마이크 입력을 사용시

<br>   

- ### 마이크 입력
[오디오 파일 듣기](./recording_input_before.wav)


- ### 입력 음성 -> 텍스트
![image](https://github.com/kccistc/intel-04/assets/127078552/d2233a67-bf68-41ba-ac7c-1f8216234b15)



- ### GPT 2 응답
![image](https://github.com/kccistc/intel-04/assets/127078552/659f1ba3-af67-4841-b067-46890aeea45f)



- ### 응답 텍스트-> 음성
[오디오 파일 듣기](./audio_before.wav)

<br>   

## 로지텍 Brio 4K Pro 마이크 입력을 사용시

<br>   

- ### 마이크 입력
[오디오 파일 듣기](./recording_input_after.wav)

- ### 입력 음성 -> 텍스트

![image](https://github.com/kccistc/intel-04/assets/127078552/e13281c8-dd5a-4b3a-bcb4-e62bd396c2fa)


- ### GPT 2 응답

![image](https://github.com/kccistc/intel-04/assets/127078552/98424575-6fb1-4452-9a14-10043c383117)


- ### 응답 텍스트-> 음성

[오디오 파일 듣기](./audio_after.wav)

<br>   

# 시연 결과 분석
   1. 음성 입력 장치에 대한 입력 품질
   2. LLM 모델 변경 검토
   3. 음성 -> 텍스트 모델 검토 필요
     
<br>   

# 프로젝트 성과 및 향후 발전 방향
- ### 프로젝트 성과 
1. 경량화하여 임베디드에 집약할 수 있을 가능성을 발견
2. 추후 프로젝트에 유동적으로 해당 개발 모듈 삽입 가능
     
<br>   

- ### 향후 발전 방향
1. 음성 -> 텍스트 변환 과정에 대한 모델 검토로 변환 과정 성능 개편 
2. 더 성능이 좋은 LLM 모델 검토로
 예상 답변 성능 개편
3. 더 정확한 음성 입력을 위한 하드웨어 변경 고려
     
<br>   
 
# 팀원 느낀점

김기범 : open model 에서 다른 여러 Speech Recognition 모델들이 있는데 시간 상 성능 비교를 통해 더 나은 모델을 만들지 못한것이 아쉽고, 또 여러 모델들을 병합 하는 과정에 있어서 조금 어려움이 있었습니다. 그리고, 팀프로젝트에 앞서서 미리 관련 모델들을 시험해 보고 확인할 수 있어서 좋았습니다.
     
<br>   

염재영 : openvino의 모델만을 활용해서 음성 인식 AI를 만든것이 신기하고 추후 메인 프로젝트에 도움이 될 기반 시스템을 개발할 수 있는 기회가 된 것 같아서 뿌듯하다.
